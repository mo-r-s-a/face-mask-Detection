{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fp3JJKVPxAG",
        "outputId": "3ec1630e-6419-49d2-9d16-4c61eeab726f"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "crawford_emnist_path = kagglehub.dataset_download('crawford/emnist')\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txyCPT09KCiA",
        "outputId": "782fbb86-72a5-4615-f751-f47d97826280"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "ashishjangra27_face_mask_12k_images_dataset_path = kagglehub.dataset_download('ashishjangra27/face-mask-12k-images-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IE6KnyyiqzVu",
        "outputId": "ae92e899-404e-4adb-e847-7c79240127d6"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKENR4l-qzVu",
        "outputId": "4bf3894a-6393-4e81-95fc-92687160d39d"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten,Dense,Conv2D,MaxPooling2D,ZeroPadding2D,Dropout\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3BzQSFYRYNB"
      },
      "outputs": [],
      "source": [
        "data_dir = ashishjangra27_face_mask_12k_images_dataset_path\n",
        "train_dir = os.path.join(data_dir, \"Face Mask Dataset/Train\")\n",
        "test_dir = os.path.join(data_dir, \"Face Mask Dataset/Test\")\n",
        "validation_dir = os.path.join(data_dir, \"Face Mask Dataset/Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XuHBxa_qzVw"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = (128, 128)\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox2CLyh8R4o_",
        "outputId": "75277608-127a-418c-96b0-ee6bc5e73025"
      },
      "outputs": [],
      "source": [
        "# Data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "val_data = val_test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "test_data = val_test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "qzg_DOb2qzVz",
        "outputId": "c9f4379c-33f7-4a2c-d8be-29a125eaa958"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(Conv2D(32, (3, 3),input_shape=(128,128,3),activation=\"relu\"))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3),activation=\"relu\"))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3),activation=\"relu\"))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
        "\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1,activation=\"sigmoid\"))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPdA8FiKqzVz"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\", metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zJ8urxrqzVz",
        "outputId": "19924e8d-e496-437c-f54c-d44301110811"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_data,validation_data=val_data,epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ErdobcWeqzV0",
        "outputId": "390e9d11-7136-4bd8-e15a-cf5f40fdaac4"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "YKKXht4JT4Yn",
        "outputId": "acef31fa-b773-4c33-8467-31e3accb4059"
      },
      "outputs": [],
      "source": [
        "# Evaluate on test data\n",
        "test_loss, test_acc = model.evaluate(test_data)\n",
        "print(f\"Test Accuracy: {test_acc:.2f}\")\n",
        "\n",
        "# Predict on test set\n",
        "preds = model.predict(test_data)\n",
        "pred_labels = (preds > 0.5).astype(\"int32\")\n",
        "\n",
        "# Show some predictions\n",
        "class_names = list(test_data.class_indices.keys())\n",
        "images, labels = next(test_data)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i in range(6):\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    plt.imshow(images[i])\n",
        "    true_label = class_names[int(labels[i])]\n",
        "    pred_label = class_names[int(pred_labels[i])]\n",
        "    color = 'green' if true_label == pred_label else 'red'\n",
        "    plt.title(f\"True: {true_label}\\nPred: {pred_label}\", color=color)\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etsN1wq4tPac"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "class DummyModel:\n",
        "    def predict(self, img):\n",
        "        return np.array([[0.3]])  # Simulated \"With Mask\"\n",
        "model1 = DummyModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "KZTVYNTFqzV1",
        "outputId": "080f3d45-d88f-4241-a375-95c46e157dad"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from PIL import Image,ImageOps\n",
        "\"\"\"def crop_center(image, cropx, cropy):\n",
        "    y, x, _ = image.shape\n",
        "    startx = x // 2 - cropx // 2\n",
        "    starty = y // 2 - cropy // 2\n",
        "    return image[starty:starty + cropy, startx:startx + cropx]\"\"\"\n",
        "\n",
        "\n",
        "def predict_digit(frame):\n",
        "    try:\n",
        "        # Convert to grayscale for detection\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        # Detect faces\n",
        "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
        "\n",
        "        if len(faces) == 0:\n",
        "            return \"No face detected.\"\n",
        "\n",
        "        x, y, w, h = faces[0]  # First face only\n",
        "        face = frame[y:y+h, x:x+w]  # Crop face\n",
        "        # Resize the image using PIL before converting to NumPy array\n",
        "\n",
        "        #frame = crop_center(frame, 20, 20)\n",
        "        image = Image.fromarray(face.astype('uint8'), 'RGB').resize((128, 128))\n",
        "        image = np.array(image) / 255.0\n",
        "        image = image.reshape(1, 128, 128, 3)\n",
        "\n",
        "        prediction = model.predict(image)\n",
        "        #pred = prediction[0]\n",
        "\n",
        "        label = \"With Mask ðŸ˜·\" if prediction < 0.5 else \"Without Mask ðŸ˜\"\n",
        "        confidence = (1 - prediction) if prediction < 0.5 else prediction\n",
        "\n",
        "        return f\"{label}\\nConfidence: {np.max(prediction)*100:0.1f}\"\n",
        "    except Exception as e:\n",
        "      return f\"Error: {e}\"\n",
        "demo = gr.Interface(\n",
        "    fn=predict_digit,\n",
        "    inputs=gr.Image(),\n",
        "    outputs=\"text\",\n",
        "    title=\"Digit Classifier\",\n",
        "    description=\"Draw a digit (0â€“9) and let the model predict it!\"\n",
        ")\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlpB9xmCrXhT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 7160,
          "sourceId": 10705,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31089,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
